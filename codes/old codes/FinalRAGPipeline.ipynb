{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a985c52-d2ed-408a-a66b-de650d78ff42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# RAG PIPELINE WITH LANGCHAIN\n",
    "# Building a Retrieval-Augmented Generation System\n",
    "# =============================================================================\n",
    "\n",
    "# =============================================================================\n",
    "# INSTALLATION (Run once per environment)\n",
    "# =============================================================================\n",
    "\n",
    "%pip install langchain langchain-community chromadb sentence-transformers \\\n",
    "             pypdf beautifulsoup4 requests python-dotenv langchain-ollama \\\n",
    "             matplotlib numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4c076e-4ea8-4498-abd4-ab074bbeaf1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Core utilities\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Tuple\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Environment & document processing\n",
    "from dotenv import load_dotenv\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader, WebBaseLoader, TextLoader\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "# Vector database & embeddings\n",
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# LLM interfaces\n",
    "from langchain_ollama.llms import OllamaLLM           # standard LLM\n",
    "from langchain_ollama.chat_models import ChatOllama  # chat interface\n",
    "from langchain_ollama.embeddings import OllamaEmbeddings\n",
    "\n",
    "\n",
    "# Web scraping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "print(\"âœ“ All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1b4ee0-7423-4153-a28a-56a75a3eb87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 2. CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Pipeline configuration\n",
    "CONFIG = {\n",
    "    'chunk_size': 1000,\n",
    "    'chunk_overlap': 200,\n",
    "    'top_k_retrieval': 5,\n",
    "    'llm_model': 'llama3.1',\n",
    "    'collection_name': 'rag_documents',\n",
    "    'embedding_model': 'all-MiniLM-L6-v2'\n",
    "}\n",
    "\n",
    "# Create project directories\n",
    "Path(\"documents\").mkdir(exist_ok=True)\n",
    "Path(\"results\").mkdir(exist_ok=True)\n",
    "\n",
    "print(\"âœ“ Configuration loaded\")\n",
    "print(f\"   LLM Model: {CONFIG['llm_model']}\")\n",
    "print(f\"   Chunk size: {CONFIG['chunk_size']}, Overlap: {CONFIG['chunk_overlap']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b577679b-06bb-4503-a921-bc5da2ac4986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 4. RAG PIPELINE OVERVIEW\n",
    "# =============================================================================\n",
    "# A. Document loading & chunking\n",
    "# B. Vector database (ChromaDB)\n",
    "# C. Retrieval-Augmented Generation (RAG)\n",
    "# D. Evaluation & benchmarking\n",
    "# E. Metrics & result analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49d535e-43ea-4b03-96c1-ddc9af3becdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEILA \n",
    "#=============================================================================\n",
    "# A. DOCUMENT LOADING & PREPROCESSING\n",
    "# =============================================================================\n",
    "\n",
    "class DocumentProcessor:\n",
    "    \"\"\"Handles loading and chunking documents from multiple sources.\"\"\"\n",
    "    \n",
    "    def __init__(self, chunk_size: int = 1000, chunk_overlap: int = 200):\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
    "        )\n",
    "        self.documents = []\n",
    "        self.chunks = []\n",
    "        print(f\"âœ“ DocumentProcessor initialized (chunk_size={chunk_size}, overlap={chunk_overlap})\")\n",
    "    \n",
    "    def load_pdf(self, pdf_path: str):\n",
    "        \"\"\"Load and process PDF document.\"\"\"\n",
    "        # TODO: Implement PDF loading\n",
    "        # 1. Use PyPDFLoader(pdf_path)\n",
    "        # 2. Load documents\n",
    "        # 3. Add to self.documents with metadata (source, type='pdf')\n",
    "        # Example:\n",
    "        # loader = PyPDFLoader(pdf_path)\n",
    "        # docs = loader.load()\n",
    "        # self.documents.extend(docs)\n",
    "        pass\n",
    "    \n",
    "    def load_text(self, text_path: str):\n",
    "        \"\"\"Load plain text file.\"\"\"\n",
    "        # TODO: Implement text file loading\n",
    "        # 1. Use TextLoader(text_path)\n",
    "        # 2. Load documents\n",
    "        # 3. Add to self.documents with metadata\n",
    "        pass\n",
    "    \n",
    "    def load_web(self, url: str):\n",
    "        \"\"\"Scrape and load web content.\"\"\"\n",
    "        # TODO: Implement web scraping\n",
    "        # 1. Use WebBaseLoader([url])\n",
    "        # 2. Load content\n",
    "        # 3. Add to self.documents with metadata (source=url, type='web')\n",
    "        pass\n",
    "    \n",
    "    def chunk_documents(self):\n",
    "        \"\"\"Split all loaded documents into chunks.\"\"\"\n",
    "        # TODO: Implement document chunking\n",
    "        # 1. Use self.text_splitter.split_documents(self.documents)\n",
    "        # 2. Store chunks in self.chunks\n",
    "        # 3. Ensure each chunk has metadata: source, chunk_id, page_number (if available)\n",
    "        pass\n",
    "    \n",
    "    def get_chunks_with_metadata(self) -> Tuple[List[str], List[Dict]]:\n",
    "        \"\"\"Return separate lists of chunk texts and metadata.\"\"\"\n",
    "        # TODO: Extract and return chunks and metadata\n",
    "        # Return: ([chunk_text1, chunk_text2, ...], [metadata1, metadata2, ...])\n",
    "        pass\n",
    "    \n",
    "    def print_stats(self):\n",
    "        \"\"\"Display document processing statistics.\"\"\"\n",
    "        print(f\"\\nðŸ“Š Document Processing Stats:\")\n",
    "        print(f\"   Total documents loaded: {len(self.documents)}\")\n",
    "        print(f\"   Total chunks created: {len(self.chunks)}\")\n",
    "        if self.chunks:\n",
    "            avg_len = sum(len(str(c.page_content)) for c in self.chunks) / len(self.chunks)\n",
    "            print(f\"   Average chunk length: {avg_len:.0f} characters\")\n",
    "\n",
    "\n",
    "# Initialize document processor\n",
    "doc_processor = DocumentProcessor(\n",
    "    chunk_size=CONFIG['chunk_size'],\n",
    "    chunk_overlap=CONFIG['chunk_overlap']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b52a04-f298-4080-a6bb-d829184ab063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DOCUMENT LOADING SECTION\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LOADING DOCUMENTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# TODO: Load your documents here\n",
    "# Example 1: Load PDFs\n",
    "pdf_files = [\n",
    "    \"documents/paper1.pdf\",\n",
    "    \"documents/paper2.pdf\",\n",
    "    \"documents/paper3.pdf\"\n",
    "]\n",
    "# for pdf in pdf_files:\n",
    "#     if Path(pdf).exists():\n",
    "#         doc_processor.load_pdf(pdf)\n",
    "#         print(f\"âœ“ Loaded: {pdf}\")\n",
    "\n",
    "# Example 2: Load web articles\n",
    "# urls = [\n",
    "#     \"https://example.com/article1\",\n",
    "#     \"https://example.com/article2\"\n",
    "# ]\n",
    "# for url in urls:\n",
    "#     doc_processor.load_web(url)\n",
    "#     print(f\"âœ“ Loaded: {url}\")\n",
    "\n",
    "# Example 3: Load text files\n",
    "# doc_processor.load_text(\"documents/textbook.txt\")\n",
    "\n",
    "print(f\"\\nâœ“ Total documents loaded: {len(doc_processor.documents)}\")\n",
    "\n",
    "# Create chunks\n",
    "doc_processor.chunk_documents()\n",
    "doc_processor.print_stats()\n",
    "\n",
    "# Preview first chunk\n",
    "if doc_processor.chunks:\n",
    "    print(\"\\nðŸ“„ First chunk preview:\")\n",
    "    print(str(doc_processor.chunks[0].page_content)[:300] + \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721f9e09-b346-4f88-8f64-c403cb09d37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MARIAM\n",
    "#=============================================================================\n",
    "# B. VECTOR DATABASE (CHROMADB)\n",
    "# =============================================================================\n",
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import List, Dict\n",
    "\n",
    "CONFIG = {'embedding_model': 'all-MiniLM-L6-v2', 'collection_name': 'test'}\n",
    "class VectorDB:\n",
    "    \"\"\"Manages vector embeddings and semantic search.\"\"\"\n",
    "    \n",
    "    def __init__(self, collection_name: str = \"rag_documents\"):\n",
    "        self.client = chromadb.Client()\n",
    "        \n",
    "        # Clear existing collection for fresh start\n",
    "        try:\n",
    "            self.client.delete_collection(name=collection_name)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        self.collection = self.client.create_collection(\n",
    "            name=collection_name,\n",
    "            metadata={\"hnsw:space\": \"cosine\"}\n",
    "        )\n",
    "        self.model = SentenceTransformer(CONFIG['embedding_model'])\n",
    "        print(f\"âœ“ VectorDB initialized (collection: {collection_name})\")\n",
    "    \n",
    "    def add_documents(self, chunks: List[str], metadata: List[Dict] = None):\n",
    "        \"\"\"Add documents to vector database.\"\"\"\n",
    "\n",
    "        if not chunks:\n",
    "            print(\"no chunks provided\")\n",
    "            return{'success':False, 'count':0}\n",
    "\n",
    "        if metadata is None:\n",
    "            metadata = [{'source': 'unknown', 'chunk_id': i} for i in range(len(chunks))]\n",
    "    \n",
    "        embeddings= self.model.encode(chunks)\n",
    "        ids=[f\"chunks{i}\" for i in range(len(chunks))]\n",
    "\n",
    "        self.collection.add(\n",
    "             ids=ids,\n",
    "             embeddings=embeddings.tolist(),\n",
    "             documents=chunks,\n",
    "             metadatas=metadata\n",
    "        )\n",
    "        \n",
    "        return {'success':True, 'count':len(chunks)}\n",
    "    \n",
    "    def search(self, query: str, top_k: int = 5) -> List[Dict]:\n",
    "        \"\"\"Search for similar documents.\"\"\"\n",
    "        \n",
    "        if self.collection.count()==0:\n",
    "            print(\"âš ï¸  Database is empty. Add documents first.\")\n",
    "            return []\n",
    "        query_embeddings=self.model.encode([query])[0]\n",
    "        \n",
    "        results=self.collection.query(\n",
    "            query_embeddings=[query_embeddings.tolist()],\n",
    "            n_results=top_k\n",
    "        )\n",
    "        \n",
    "        formatted_results=[]\n",
    "        for i in range(len(results['ids'][0])):\n",
    "            formatted_results.append({\n",
    "                'chunk': results['documents'][0][i],      # Original text\n",
    "                'score': 1 - results['distances'][0][i],  # Convert distance to similarity\n",
    "                'metadata': results['metadatas'][0][i],   # Source info\n",
    "                'id': results['ids'][0][i]                # Chunk ID\n",
    "            })\n",
    "        \n",
    "        return formatted_results\n",
    "    \n",
    "    def get_stats(self) -> Dict:\n",
    "        \"\"\"Return database statistics.\"\"\"\n",
    "        return {\n",
    "            'total_chunks': self.collection.count(),\n",
    "            'embedding_model': CONFIG['embedding_model'],\n",
    "            'embedding_dimensions': self.model.get_sentence_embedding_dimension(),\n",
    "            'database': 'ChromaDB',\n",
    "            'similarity_metric':'cosine'\n",
    "        }\n",
    "\n",
    "\n",
    "    def clear_database(self):\n",
    "        \"\"\"Delete all documents from the collection.\"\"\"\n",
    "        collection_name = self.collection.name\n",
    "        self.client.delete_collection(name=collection_name)\n",
    "        self.collection = self.client.create_collection(\n",
    "            name=collection_name,\n",
    "            metadata={\"hnsw:space\": \"cosine\"}\n",
    "        )\n",
    "        print(f\"âœ“ Database cleared\")\n",
    "\n",
    "# Initialize vector database\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VECTOR DATABASE SETUP\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "vector_db = VectorDB(collection_name=CONFIG['collection_name'])\n",
    "\n",
    "# TODO: Populate vector database\n",
    "# chunks_text, chunks_metadata = doc_processor.get_chunks_with_metadata()\n",
    "# vector_db.add_documents(chunks_text, chunks_metadata)\n",
    "\n",
    "# Display stats\n",
    "if result['success']:\n",
    "    stats = vector_db.get_stats()\n",
    "    print(f\"\\nðŸ“Š Vector Database Stats:\")\n",
    "    for key, value in stats.items():\n",
    "        print(f\"   {key}: {value}\")\n",
    "\n",
    "# Test search functionality\n",
    "print(\"\\nðŸ” Testing vector search...\")\n",
    "# test_query = \"What is retrieval-augmented generation?\"\n",
    "# results = vector_db.search(test_query, top_k=3)\n",
    "# for i, result in enumerate(results, 1):\n",
    "#     print(f\"\\nResult {i} (Score: {result['score']:.3f}):\")\n",
    "#     print(f\"Source: {result['metadata'].get('source', 'unknown')}\")\n",
    "#     print(f\"Text: {result['chunk'][:150]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9d0c2c-c147-4545-8fa5-a5eebd8eaade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERZHINIA \n",
    "#=============================================================================\n",
    "# C. RAG PIPELINE CONSTRUCTION\n",
    "# =============================================================================\n",
    "\n",
    "# Define RAG prompt template\n",
    "RAG_PROMPT_TEMPLATE = \"\"\"You are a helpful AI assistant. Answer the question based ONLY on the provided context.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Instructions:\n",
    "- Answer using ONLY information from the context above\n",
    "- If the context doesn't contain relevant information, say: \"I don't have enough information to answer this question.\"\n",
    "- Cite sources when possible\n",
    "- Be concise and accurate\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template=RAG_PROMPT_TEMPLATE,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "\n",
    "class RAGPipeline:\n",
    "    \"\"\"Complete RAG pipeline: retrieve â†’ format â†’ generate.\"\"\"\n",
    "    \n",
    "    def __init__(self, vector_db: VectorDB, llm_model: str, top_k: int = 5):\n",
    "        self.vector_db = vector_db\n",
    "        self.top_k = top_k\n",
    "        self.prompt_template = prompt_template\n",
    "        \n",
    "        # Initialize LLM (choose based on model name)\n",
    "        if 'gpt' in llm_model:\n",
    "            self.llm = ChatOpenAI(model=llm_model, temperature=0)\n",
    "        else:\n",
    "            # For Ollama local models\n",
    "            from langchain_ollama import Ollama\n",
    "            self.llm = Ollama(model=llm_model)\n",
    "        \n",
    "        print(f\"âœ“ RAG Pipeline initialized with {llm_model}\")\n",
    "    \n",
    "    def retrieve(self, query: str) -> List[Dict]:\n",
    "        \"\"\"Retrieve relevant chunks from vector database.\"\"\"\n",
    "        # TODO: Use self.vector_db.search() to get top_k results\n",
    "        pass\n",
    "    \n",
    "    def format_context(self, retrieved_chunks: List[Dict]) -> str:\n",
    "        \"\"\"Format retrieved chunks into context string.\"\"\"\n",
    "        # TODO: Combine chunks into single context string\n",
    "        # Include source information for citations\n",
    "        # Example format:\n",
    "        # Source 1 (document.pdf):\n",
    "        # [chunk text]\n",
    "        # \n",
    "        # Source 2 (article.txt):\n",
    "        # [chunk text]\n",
    "        pass\n",
    "    \n",
    "    def generate_response(self, query: str) -> Dict:\n",
    "        \"\"\"Complete RAG pipeline: retrieve + generate.\"\"\"\n",
    "        # TODO: Implement full RAG flow\n",
    "        # 1. Retrieve relevant chunks\n",
    "        # 2. Format context\n",
    "        # 3. Create prompt using self.prompt_template\n",
    "        # 4. Generate response with self.llm\n",
    "        # 5. Return dict with: answer, sources, retrieved_chunks\n",
    "        pass\n",
    "    \n",
    "    def query(self, question: str, return_sources: bool = True) -> Dict:\n",
    "        \"\"\"User-facing query method.\"\"\"\n",
    "        return self.generate_response(question)\n",
    "\n",
    "\n",
    "# Initialize RAG pipeline\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RAG PIPELINE INITIALIZATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "rag_pipeline = RAGPipeline(\n",
    "    vector_db=vector_db,\n",
    "    llm_model=CONFIG['llm_model'],\n",
    "    top_k=CONFIG['top_k_retrieval']\n",
    ")\n",
    "\n",
    "# Test RAG pipeline\n",
    "print(\"\\nðŸ§ª Testing RAG pipeline...\")\n",
    "# test_question = \"What are the main components of a RAG system?\"\n",
    "# response = rag_pipeline.query(test_question)\n",
    "# print(f\"\\nâ“ Question: {test_question}\")\n",
    "# print(f\"\\nâœ… Answer: {response['answer']}\")\n",
    "# print(f\"\\nðŸ“š Sources: {', '.join(response['sources'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2a1f31-2072-43c9-979e-5f920feb75f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HASSAN\n",
    "#=============================================================================\n",
    "# D. EVALUATION & TESTING\n",
    "# =============================================================================\n",
    "\n",
    "# Define test queries across different categories\n",
    "TEST_QUERIES = {\n",
    "    'factual_in_scope': [\n",
    "        # TODO: Add questions that ARE answered in your documents\n",
    "        \"What is RAG?\",\n",
    "        \"How does vector search work?\",\n",
    "    ],\n",
    "    'synthesis': [\n",
    "        # TODO: Add questions requiring multiple chunks\n",
    "        \"Compare different approaches to document chunking\",\n",
    "    ],\n",
    "    'out_of_scope': [\n",
    "        # TODO: Add questions NOT in your documents\n",
    "        \"What is the weather today?\",\n",
    "    ],\n",
    "    'misleading': [\n",
    "        # TODO: Add questions with false premises\n",
    "        \"Why is RAG less effective than keyword search?\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EVALUATION & TESTING\")\n",
    "print(\"=\"*60)\n",
    "print(f\"âœ“ Test dataset created with {sum(len(v) for v in TEST_QUERIES.values())} queries\")\n",
    "\n",
    "\n",
    "def run_rag_tests():\n",
    "    \"\"\"Test RAG pipeline across all query categories.\"\"\"\n",
    "    # TODO: Implement RAG testing\n",
    "    # 1. Loop through TEST_QUERIES\n",
    "    # 2. For each query, call rag_pipeline.query()\n",
    "    # 3. Record: category, query, answer, sources, response_time\n",
    "    # 4. Store results in list\n",
    "    # 5. Return results\n",
    "    pass\n",
    "\n",
    "\n",
    "def run_base_llm_tests():\n",
    "    \"\"\"Test base LLM without RAG for comparison.\"\"\"\n",
    "    # TODO: Implement base LLM testing\n",
    "    # 1. Initialize base LLM (without RAG)\n",
    "    # 2. Test same queries\n",
    "    # 3. Record: category, query, answer, response_time\n",
    "    # 4. Return results\n",
    "    pass\n",
    "\n",
    "\n",
    "# Run tests\n",
    "# rag_results = run_rag_tests()\n",
    "# base_results = run_base_llm_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e91667-d2d4-4cc1-a56b-6741e3f1dba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUMI\n",
    "#=============================================================================\n",
    "# E. EVALUATION METRICS (OPTIONAL)\n",
    "# =============================================================================\n",
    "\n",
    "class RAGEvaluator:\n",
    "    \"\"\"Evaluate RAG system performance.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.metrics = []\n",
    "    \n",
    "    def evaluate_faithfulness(self, answer: str, retrieved_chunks: List[str]) -> float:\n",
    "        \"\"\"Check if answer is grounded in retrieved chunks.\"\"\"\n",
    "        # TODO: Implement faithfulness scoring\n",
    "        # Simple approach: check if answer phrases appear in chunks\n",
    "        # Advanced: use LLM to verify claims\n",
    "        # Return score 0-1\n",
    "        pass\n",
    "    \n",
    "    def evaluate_relevance(self, query: str, answer: str) -> float:\n",
    "        \"\"\"Check if answer is relevant to query.\"\"\"\n",
    "        # TODO: Implement relevance scoring\n",
    "        # Use embedding similarity between query and answer\n",
    "        # Return score 0-1\n",
    "        pass\n",
    "    \n",
    "    def detect_hallucination(self, answer: str, retrieved_chunks: List[str]) -> bool:\n",
    "        \"\"\"Detect if answer contains unsupported claims.\"\"\"\n",
    "        # TODO: Implement hallucination detection\n",
    "        # Check for \"I don't know\" responses vs specific claims\n",
    "        # Verify claims appear in chunks\n",
    "        # Return True if hallucination detected\n",
    "        pass\n",
    "    \n",
    "    def evaluate_response(self, query: str, answer: str, retrieved_chunks: List[str]) -> Dict:\n",
    "        \"\"\"Run all evaluation metrics.\"\"\"\n",
    "        # TODO: Call all evaluation methods\n",
    "        # Return dict with all scores\n",
    "        pass\n",
    "    \n",
    "    def aggregate_results(self) -> Dict:\n",
    "        \"\"\"Calculate aggregate metrics across all queries.\"\"\"\n",
    "        # TODO: Average all metrics\n",
    "        # Return summary statistics\n",
    "        pass\n",
    "\n",
    "\n",
    "# evaluator = RAGEvaluator()\n",
    "# TODO: Evaluate all RAG results and calculate aggregate metrics"
   ]


  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c801e8-31f4-4f5c-a534-a50915740ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# RESULTS & VISUALIZATION\n",
    "# =============================================================================\n",
    "\n",
    "def save_results(rag_results, base_results, aggregate_metrics):\n",
    "    \"\"\"Save evaluation results to JSON file.\"\"\"\n",
    "    # TODO: Create results dictionary\n",
    "    # Include: config, stats, results, metrics, timestamp\n",
    "    # Save to results/rag_evaluation_{timestamp}.json\n",
    "    pass\n",
    "\n",
    "\n",
    "def visualize_results(rag_results, base_results):\n",
    "    \"\"\"Create visualizations comparing RAG vs base LLM.\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('RAG Pipeline Evaluation Results', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Response Time Distribution\n",
    "    if rag_results:\n",
    "        response_times = [r.get('response_time', 0) for r in rag_results]\n",
    "        axes[0, 0].hist(response_times, bins=20, color='skyblue', edgecolor='black')\n",
    "        axes[0, 0].set_title('Response Time Distribution')\n",
    "        axes[0, 0].set_xlabel('Time (seconds)')\n",
    "        axes[0, 0].set_ylabel('Frequency')\n",
    "        axes[0, 0].axvline(np.mean(response_times), color='red', \n",
    "                          linestyle='--', label=f'Mean: {np.mean(response_times):.2f}s')\n",
    "        axes[0, 0].legend()\n",
    "\n",
    "    \n",
    "    # 2. Success Rate by Category\n",
    "    if rag_results:\n",
    "        categories = {}\n",
    "        for result in rag_results:\n",
    "            cat = result.get('category', 'unknown')\n",
    "            categories[cat] = categories.get(cat, 0) + 1\n",
    "        \n",
    "        axes[0, 1].bar(categories.keys(), categories.values(), color='lightgreen', edgecolor='black')\n",
    "        axes[0, 1].set_title('Queries by Category')\n",
    "        axes[0, 1].set_xlabel('Category')\n",
    "        axes[0, 1].set_ylabel('Count')\n",
    "        axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    # 3. RAG vs Base LLM Comparison\n",
    "    if base_results:\n",
    "        metrics = ['Faithfulness', 'Relevance']\n",
    "        rag_scores = [0.8, 0.85]  # Example values\n",
    "        base_scores = [0.5, 0.6]\n",
    "        \n",
    "        x = np.arange(len(metrics))\n",
    "        width = 0.35\n",
    "        \n",
    "        axes[1, 0].bar(x - width/2, rag_scores, width, label='RAG', color='cornflowerblue')\n",
    "        axes[1, 0].bar(x + width/2, base_scores, width, label='Base LLM', color='lightcoral')\n",
    "        axes[1, 0].set_title('RAG vs Base LLM Performance')\n",
    "        axes[1, 0].set_ylabel('Score')\n",
    "        axes[1, 0].set_xticks(x)\n",
    "        axes[1, 0].set_xticklabels(metrics)\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].set_ylim([0, 1])\n",
    "\n",
    "\n",
    "# Save and visualize results\n",
    "# save_results(rag_results, base_results, aggregate_metrics)\n",
    "# visualize_results(rag_results, base_results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FRAMEWORK COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(\"Next steps:\")\n",
    "print(\"1. Implement all TODO sections\")\n",
    "print(\"2. Load your documents (Section A)\")\n",
    "print(\"3. Test retrieval and generation\")\n",
    "print(\"4. Run evaluation tests\")\n",
    "print(\"5. Prepare presentation materials\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b109ba2f-813b-497b-9bcd-a68cfd5a78dd",
   "metadata": {},
   "source": [
    "1. finish code(all) (rumi's part(hasan) & visualization(mariam)\n",
    "2. documentation (all)\n",
    "3. presentation (leila)\n",
    "4. UI (verzhi)\n",
    "\n",
    "online- meeting 15th Jan\n",
    "on- campus meeting 19th Jan"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (RAG)",
   "language": "python",
   "name": "rag_py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
